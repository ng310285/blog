#
# Spark cluster setup for docker-compose
#
# Inspiration from: https://grzegorzgajda.gitbooks.io/spark-examples/content/basics/docker.html
#

spark-master:
    image: spark-2
    command: sh -c "/usr/local/spark-1.6.2-bin-hadoop2.6/bin/spark-class org.apache.spark.deploy.master.Master -h spark-master& 2>&1; /usr/local/livy-server-0.2.0/bin/livy-server"
    hostname: spark-master
    environment:
      MASTER: spark://spark-master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: 127.0.0.1
      SPARK_HOME: /usr/local/spark-1.6.2-bin-hadoop2.6
    expose:
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
      - 6066
      - 8998
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080
      - 8998:8998
    volumes:
      - ./conf/spark-master:/conf
      - ./data:/tmp/data  

spark-worker-1:
    image: spark-2
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    hostname: spark-worker-1
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: 127.0.0.1
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
    links:
      - spark-master
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8081:8081
    volumes:
      - ./conf/spark-worker-1:/conf
      - ./data:/tmp/data
